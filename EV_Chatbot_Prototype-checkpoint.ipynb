{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "664b6c76-8364-4ba0-a397-29f2dfca26ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in 'data': ['.ipynb_checkpoints', 'ElectricCarData_Clean.csv']\n",
      "Current folder: D:\\Btech\\Ai integrated\\EV-Green-Chatbot\n"
     ]
    }
   ],
   "source": [
    "# Install if needed (run in cmd if errors: pip install pandas scikit-learn joblib matplotlib)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Quick check: List files in data folder to confirm CSV name\n",
    "print(\"Files in 'data':\", os.listdir('data'))\n",
    "print(\"Current folder:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e645db-ccfc-4db4-97ab-e76f771715e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (rows x columns): (103, 14)\n",
      "\n",
      "First 5 rows:\n",
      "         Brand                          Model  AccelSec  TopSpeed_KmH  \\\n",
      "0       Tesla   Model 3 Long Range Dual Motor       4.6           233   \n",
      "1  Volkswagen                       ID.3 Pure      10.0           160   \n",
      "2    Polestar                               2       4.7           210   \n",
      "3         BMW                            iX3        6.8           180   \n",
      "4       Honda                              e        9.5           145   \n",
      "\n",
      "   Range_Km  Efficiency_WhKm FastCharge_KmH RapidCharge PowerTrain  \\\n",
      "0       450              161            940         Yes        AWD   \n",
      "1       270              167            250         Yes        RWD   \n",
      "2       400              181            620         Yes        AWD   \n",
      "3       360              206            560         Yes        RWD   \n",
      "4       170              168            190         Yes        RWD   \n",
      "\n",
      "     PlugType  BodyStyle Segment  Seats  PriceEuro  \n",
      "0  Type 2 CCS      Sedan       D      5      55480  \n",
      "1  Type 2 CCS  Hatchback       C      5      30000  \n",
      "2  Type 2 CCS   Liftback       D      5      56440  \n",
      "3  Type 2 CCS        SUV       D      5      68040  \n",
      "4  Type 2 CCS  Hatchback       B      4      32997  \n",
      "\n",
      "Column names:\n",
      "['Brand', 'Model', 'AccelSec', 'TopSpeed_KmH', 'Range_Km', 'Efficiency_WhKm', 'FastCharge_KmH', 'RapidCharge', 'PowerTrain', 'PlugType', 'BodyStyle', 'Segment', 'Seats', 'PriceEuro']\n",
      "\n",
      "Missing values per column:\n",
      "Brand              0\n",
      "Model              0\n",
      "AccelSec           0\n",
      "TopSpeed_KmH       0\n",
      "Range_Km           0\n",
      "Efficiency_WhKm    0\n",
      "FastCharge_KmH     0\n",
      "RapidCharge        0\n",
      "PowerTrain         0\n",
      "PlugType           0\n",
      "BodyStyle          0\n",
      "Segment            0\n",
      "Seats              0\n",
      "PriceEuro          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load CSV - Using EXACT name from your output\n",
    "csv_name = 'ElectricCarData_Clean.csv'  # This matches your file\n",
    "df = pd.read_csv(f'data/{csv_name}')\n",
    "\n",
    "# Basic info\n",
    "print(\"Dataset size (rows x columns):\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450bc68f-57d1-4188-95b5-59769872e3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Features Shape: (103, 10)\n",
      "\n",
      "Sample Features (X):\n",
      "   AccelSec  TopSpeed_KmH  Range_Km  Efficiency_WhKm  Seats FastCharge_KmH  \\\n",
      "0       4.6           233       450              161      5            940   \n",
      "1      10.0           160       270              167      5            250   \n",
      "2       4.7           210       400              181      5            620   \n",
      "3       6.8           180       360              206      5            560   \n",
      "4       9.5           145       170              168      4            190   \n",
      "\n",
      "         Brand PowerTrain  BodyStyle Segment  \n",
      "0       Tesla         AWD      Sedan       D  \n",
      "1  Volkswagen         RWD  Hatchback       C  \n",
      "2    Polestar         AWD   Liftback       D  \n",
      "3         BMW         RWD        SUV       D  \n",
      "4       Honda         RWD  Hatchback       B  \n",
      "\n",
      "Target Sample (Prices):\n",
      "0    55480\n",
      "1    30000\n",
      "2    56440\n",
      "3    68040\n",
      "4    32997\n",
      "Name: PriceEuro, dtype: int64\n",
      "\n",
      "Green Example: Efficiency km/kWh for first 5:\n",
      "0    6.211180\n",
      "1    5.988024\n",
      "2    5.524862\n",
      "3    4.854369\n",
      "4    5.952381\n",
      "Name: Efficiency_KmKWh, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Clean & Engineer Features (handles categoricals/numerics)\n",
    "# Drop any unnamed (none here, but safe)\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Price to numeric (already good, but ensure)\n",
    "df['PriceEuro'] = pd.to_numeric(df['PriceEuro'], errors='coerce')\n",
    "df = df.dropna(subset=['PriceEuro'])  # No change since clean\n",
    "\n",
    "# Engineer Green Feature: Efficiency to km/kWh (higher = greener; range / efficiency = score)\n",
    "df['Efficiency_KmKWh'] = 1000 / df['Efficiency_WhKm']  # e.g., 161 Wh/km -> ~6.21 km/kWh\n",
    "\n",
    "# Select Features (inputs) & Target (price)\n",
    "numerical_cols = ['AccelSec', 'TopSpeed_KmH', 'Range_Km', 'Efficiency_WhKm', 'Seats', 'FastCharge_KmH']  # Add fast charge\n",
    "categorical_cols = ['Brand', 'PowerTrain', 'BodyStyle', 'Segment']  # Brands, etc. (drop 'Model'/'PlugType' for simplicity)\n",
    "\n",
    "# Verify columns exist (prints if missing)\n",
    "missing = [col for col in numerical_cols + categorical_cols if col not in df.columns]\n",
    "if missing:\n",
    "    print(\"Warning: Missing columns:\", missing)\n",
    "    # Auto-remove them\n",
    "    numerical_cols = [col for col in numerical_cols if col in df.columns]\n",
    "    categorical_cols = [col for col in categorical_cols if col in df.columns]\n",
    "\n",
    "X = df[numerical_cols + categorical_cols]  # Features\n",
    "y = df['PriceEuro']  # Target\n",
    "\n",
    "print(\"Preprocessed Features Shape:\", X.shape)\n",
    "print(\"\\nSample Features (X):\")\n",
    "print(X.head())\n",
    "print(\"\\nTarget Sample (Prices):\")\n",
    "print(y.head())\n",
    "print(\"\\nGreen Example: Efficiency km/kWh for first 5:\")\n",
    "print(df['Efficiency_KmKWh'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "571387ef-771f-479a-a39e-bb167d78174a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Shape (after cleaning): (98, 11)\n",
      "Rows dropped due to '-': 5\n",
      "\n",
      "Sample X (now all numeric):\n",
      "   AccelSec  TopSpeed_KmH  Range_Km  Efficiency_WhKm  Seats  FastCharge_KmH  \\\n",
      "0       4.6         233.0     450.0            161.0    5.0           940.0   \n",
      "1      10.0         160.0     270.0            167.0    5.0           250.0   \n",
      "2       4.7         210.0     400.0            181.0    5.0           620.0   \n",
      "3       6.8         180.0     360.0            206.0    5.0           560.0   \n",
      "4       9.5         145.0     170.0            168.0    4.0           190.0   \n",
      "\n",
      "   Efficiency_KmKWh        Brand PowerTrain  BodyStyle Segment  \n",
      "0          6.211180       Tesla         AWD      Sedan       D  \n",
      "1          5.988024  Volkswagen         RWD  Hatchback       C  \n",
      "2          5.524862    Polestar         AWD   Liftback       D  \n",
      "3          4.854369         BMW         RWD        SUV       D  \n",
      "4          5.952381       Honda         RWD  Hatchback       B  \n",
      "\n",
      "Any '-' left? Check FastCharge:\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # Add this if not imported\n",
    "\n",
    "# Clean & Engineer Features\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Key Fix: Replace '-' with NaN in numerical columns, then to float\n",
    "for col in numerical_cols:  # Use our list\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].replace('-', np.nan).astype(float)\n",
    "\n",
    "df['PriceEuro'] = pd.to_numeric(df['PriceEuro'], errors='coerce')\n",
    "\n",
    "# Engineer Green Feature\n",
    "if 'Efficiency_WhKm' in df.columns:\n",
    "    df['Efficiency_KmKWh'] = 1000 / df['Efficiency_WhKm']\n",
    "\n",
    "# Update numerical_cols to include engineered (if exists)\n",
    "if 'Efficiency_KmKWh' in df.columns:\n",
    "    if 'Efficiency_KmKWh' not in numerical_cols:\n",
    "        numerical_cols.append('Efficiency_KmKWh')\n",
    "\n",
    "# Drop rows with any missing in features/target (safe for 103 rows)\n",
    "df = df.dropna(subset=numerical_cols + ['PriceEuro'])\n",
    "\n",
    "categorical_cols = ['Brand', 'PowerTrain', 'BodyStyle', 'Segment']\n",
    "\n",
    "# Verify columns\n",
    "missing = [col for col in numerical_cols + categorical_cols if col not in df.columns]\n",
    "if missing:\n",
    "    print(\"Missing columns:\", missing)\n",
    "    numerical_cols = [col for col in numerical_cols if col in df.columns]\n",
    "    categorical_cols = [col for col in categorical_cols if col in df.columns]\n",
    "\n",
    "X = df[numerical_cols + categorical_cols]\n",
    "y = df['PriceEuro']\n",
    "\n",
    "print(\"Preprocessed Shape (after cleaning):\", X.shape)\n",
    "print(\"Rows dropped due to '-':\", 103 - len(df))  # Original 103\n",
    "print(\"\\nSample X (now all numeric):\")\n",
    "print(X.head())\n",
    "print(\"\\nAny '-' left? Check FastCharge:\")\n",
    "print(df['FastCharge_KmH'].dtype)  # Should be float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e03bf4cd-05af-4169-9cd0-2c60465caba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained!\n",
      "R² Score: 0.881 (0.7+ = solid for 98 samples)\n",
      "MAE: €6822 (avg error)\n",
      "\n",
      "Sample Predictions vs Actual:\n",
      "Pred: €67040 | Actual: €75351 | Diff: €8311\n",
      "Pred: €99832 | Actual: €79990 | Diff: €19842\n",
      "Pred: €76111 | Actual: €96050 | Diff: €19939\n",
      "Pred: €35361 | Actual: €30000 | Diff: €5361\n",
      "Pred: €35862 | Actual: €34900 | Diff: €962\n",
      "\n",
      "Top 5 Price Drivers:\n",
      "cat__Segment_F    0.299713\n",
      "AccelSec          0.271766\n",
      "TopSpeed_KmH      0.174441\n",
      "Range_Km          0.059624\n",
      "FastCharge_KmH    0.043294\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Preprocessor: Scales numbers, encodes categories\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import pandas as pd  # For importances\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),  # Now includes Efficiency_KmKWh\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Process & Split\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict & Score\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model Trained!\")\n",
    "print(f\"R² Score: {r2:.3f} (0.7+ = solid for 98 samples)\")\n",
    "print(f\"MAE: €{mae:.0f} (avg error)\")\n",
    "print(\"\\nSample Predictions vs Actual:\")\n",
    "for i in range(min(5, len(y_test))):\n",
    "    print(f\"Pred: €{y_pred[i]:.0f} | Actual: €{y_test.iloc[i]:.0f} | Diff: €{abs(y_pred[i] - y_test.iloc[i]):.0f}\")\n",
    "\n",
    "# Top Features\n",
    "feature_names = numerical_cols + [f'cat__{name.replace(\" \", \"_\")}' for name in preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)]  # Fix spacing\n",
    "importances = pd.Series(model.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
    "print(\"\\nTop 5 Price Drivers:\")\n",
    "print(importances.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "047f3597-bfc5-4e15-a2b1-5ab48604171a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved! Check /models folder for .pkl files (your trained brain).\n",
      "\n",
      "Test EV: BMW AWD SUV (350km range, 5s accel) → Predicted Price: €52321\n",
      "Real check: Similar BMW iX3 ~€68K—close?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib  # For saving\n",
    "\n",
    "# Create models folder\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save model, preprocessor, & cols (for later loading)\n",
    "joblib.dump(model, 'models/ev_model.pkl')\n",
    "joblib.dump(preprocessor, 'models/preprocessor.pkl')\n",
    "joblib.dump({'numerical_cols': numerical_cols, 'categorical_cols': categorical_cols}, 'models/cols.pkl')\n",
    "\n",
    "print(\"Saved! Check /models folder for .pkl files (your trained brain).\")\n",
    "\n",
    "# Test Prediction: Fake new EV (e.g., \"Mid-range SUV: 350km range, 5s accel, BMW, AWD, SUV, D-segment\")\n",
    "test_features = pd.DataFrame({\n",
    "    'AccelSec': [5.0], 'TopSpeed_KmH': [200.0], 'Range_Km': [350.0],\n",
    "    'Efficiency_WhKm': [170.0], 'Seats': [5.0], 'FastCharge_KmH': [500.0],\n",
    "    'Brand': ['BMW'], 'PowerTrain': ['AWD'], 'BodyStyle': ['SUV'], 'Segment': ['D']\n",
    "})\n",
    "\n",
    "# Add Efficiency_KmKWh if used\n",
    "test_features['Efficiency_KmKWh'] = 1000 / test_features['Efficiency_WhKm']\n",
    "\n",
    "# Prep & Predict\n",
    "X_test_new = test_features[numerical_cols + categorical_cols]\n",
    "X_test_processed = preprocessor.transform(X_test_new)\n",
    "pred_price = model.predict(X_test_processed)[0]\n",
    "print(f\"\\nTest EV: BMW AWD SUV (350km range, 5s accel) → Predicted Price: €{pred_price:.0f}\")\n",
    "print(\"Real check: Similar BMW iX3 ~€68K—close?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa7590a2-a806-4ca4-95c4-e7f4127de29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a395d27e3b40c6a9dee30736bb8c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DHRUV\\AppData\\Roaming\\Python\\Python313\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DHRUV\\.cache\\huggingface\\hub\\models--distilgpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f843c6c0b7784f92be3dd63ce87b0be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b44724c7388451f90f3b9cf7d21e84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6caaf2fe7f46f1a9847340fa8875c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc449d00f4f4da99902c4772cd9cf52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8985d889e07a44a48c7d4dca610b7893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520e261895ab4ad39ee8966cbf0103fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen AI Loaded! Test:\n",
      "Hello, EV world!\n",
      "Since I was a teenager, I found myself thinking, How can I get better with the new tech? And how can I be more productive with the new tech?\n",
      "I was thinking about it on my blog, and I decided to take a look at how to improve my skills.\n",
      "I‪m going to be doing this. I‪m going to be doing this. I‪m going to be doing this. I‪m going to be doing this. I‪m going to be doing this. I‪m going to be doing this. I‪m going to be doing this. I‪m going to be doing this. I‪m going to be doing this. I‪m going to be doing this. I‪m going to be doing this. I‪m going to be doing this. I‪m going to be doing this. I‪m going to be doing this. I‪m going to be doing this. I‪m going to be doing this. I‪m going to be doing this. I‪m going to be doing this. I‪m going to be doing this. I‪m going to be\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "generator = pipeline('text-generation', model='distilgpt2', device=-1)  # CPU mode\n",
    "\n",
    "print(\"Gen AI Loaded! Test:\")\n",
    "test_prompt = \"Hello, EV world!\"\n",
    "response = generator(test_prompt, max_length=20, num_return_sequences=1)[0]['generated_text']\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdcbf091-941d-4c43-ba70-17a2a6a03a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Used defaults—query unclear.\n",
      "Extracted: {'Brand': 'Generic', 'Range_Km': 300, 'AccelSec': 6.0, 'TopSpeed_KmH': 200, 'Efficiency_WhKm': 170, 'Seats': 5, 'FastCharge_KmH': 400, 'PowerTrain': 'RWD', 'BodyStyle': 'Sedan', 'Segment': 'C', 'Efficiency_KmKWh': 5.882352941176471}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "\n",
    "def extract_features(user_input):\n",
    "    prompt = f\"\"\"Extract EV features as Python dict from user query: '{user_input}'.\n",
    "    Use dataset columns: Brand (e.g., 'Tesla'), Range_Km (int, default 300), AccelSec (float, default 6.0),\n",
    "    TopSpeed_KmH (int, default 200), Efficiency_WhKm (int, default 170), Seats (int, default 5),\n",
    "    FastCharge_KmH (int, default 400), PowerTrain (e.g., 'AWD'/'RWD', default 'RWD'),\n",
    "    BodyStyle (e.g., 'SUV'/'Sedan', default 'Sedan'), Segment (e.g., 'D', default 'C').\n",
    "    Output ONLY the dict, e.g., {{'Brand': 'Tesla', 'Range_Km': 400, ...}}\"\"\"\n",
    "\n",
    "    response = generator(prompt, max_length=200, num_return_sequences=1, temperature=0.3)[0]['generated_text']\n",
    "\n",
    "    try:\n",
    "        dict_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "        if dict_match:\n",
    "            features_str = dict_match.group(0)\n",
    "            features = ast.literal_eval(features_str)\n",
    "        else:\n",
    "            raise ValueError(\"No dict found\")\n",
    "    except:\n",
    "        features = {\n",
    "            'Brand': 'Generic', 'Range_Km': 300, 'AccelSec': 6.0, 'TopSpeed_KmH': 200,\n",
    "            'Efficiency_WhKm': 170, 'Seats': 5, 'FastCharge_KmH': 400,\n",
    "            'PowerTrain': 'RWD', 'BodyStyle': 'Sedan', 'Segment': 'C'\n",
    "        }\n",
    "        print(\"Warning: Used defaults—query unclear.\")\n",
    "\n",
    "    features['Efficiency_KmKWh'] = 1000 / features['Efficiency_WhKm']\n",
    "    print(f\"Extracted: {features}\")\n",
    "    return features\n",
    "\n",
    "# Test\n",
    "user_query = \"Luxury Tesla SUV with 400km range, AWD, 4.5s accel\"\n",
    "test_features = extract_features(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc2403e2-611f-42e8-a479-fb5725816bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: €47596\n",
      "Explanation: _WhkmH = 30, 'Efficiency_WhkmH': 300, 'AccelSec': 6.0, 'TopSpeed_KmH': 400, 'PowerTrain': 'RWD', 'BodyStyle': 'Sedan', 'Segment': 'C', 'Efficiency_KmWh': 5.882352941176471}.\n"
     ]
    }
   ],
   "source": [
    "def generate_explanation(price, features):\n",
    "    # Improved prompt: Force clean, eco-focused output (no echo)\n",
    "    prompt = f\"Write a short EV price explanation (~50 words): Price €{price:.0f} for {features['Brand']} {features['BodyStyle']} with {features['Range_Km']}km range, {features['PowerTrain']}, {features['AccelSec']}s accel. Highlight cost drivers + green tip on efficiency {features['Efficiency_KmKWh']:.1f} km/kWh (higher = greener, lower emissions). End with eco suggestion.\"\n",
    "\n",
    "    response = generator(prompt, max_length=120, num_return_sequences=1, temperature=0.7, do_sample=True)[0]['generated_text']\n",
    "\n",
    "    # Better extraction: Trim prompt + clean up\n",
    "    explanation = response.replace(prompt, '').strip()  # Remove echoed prompt\n",
    "    explanation = ' '.join(explanation.split()[:25])  # Limit to ~50 words, trim junk\n",
    "\n",
    "    if len(explanation) < 20:  # Fallback if too short\n",
    "        explanation = f\"This {features['Brand']} EV costs ~€{price:.0f} due to range and features. Green tip: {features['Efficiency_KmKWh']:.1f} km/kWh efficiency saves CO2—pair with home solar!\"\n",
    "\n",
    "    return explanation\n",
    "\n",
    "# Load & Predict (same as before)\n",
    "import joblib\n",
    "import pandas as pd\n",
    "model = joblib.load('models/ev_model.pkl')\n",
    "preprocessor = joblib.load('models/preprocessor.pkl')\n",
    "cols = joblib.load('models/cols.pkl')\n",
    "numerical_cols = cols['numerical_cols']\n",
    "categorical_cols = cols['categorical_cols']\n",
    "\n",
    "test_df = pd.DataFrame([test_features])\n",
    "X_test_prep = test_df[numerical_cols + categorical_cols]\n",
    "X_test_processed = preprocessor.transform(X_test_prep)\n",
    "test_price = model.predict(X_test_processed)[0]\n",
    "\n",
    "explanation = generate_explanation(test_price, test_features)\n",
    "print(f\"Predicted: €{test_price:.0f}\\nExplanation: {explanation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02378ec-a088-4429-b1dc-7a9c92f7e7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
